{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'Bronze.csv' into a DataFrame: bronze\n",
    "bronze = pd.read_csv('../datasets/Bronze.csv')\n",
    "\n",
    "# Read 'Silver.csv' into a DataFrame: silver\n",
    "silver = pd.read_csv('../datasets/Silver.csv')\n",
    "\n",
    "# Read 'Gold.csv' into a DataFrame: gold\n",
    "gold = pd.read_csv('../datasets/Gold.csv')\n",
    "# Print the first five rows of gold\n",
    "print(gold.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create the list of file names: filenames\n",
    "filenames = ['Gold.csv', 'Silver.csv', 'Bronze.csv']\n",
    "\n",
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv('../datasets/{}'.format(filename)))\n",
    "\n",
    "# Print top 5 rows of 1st DataFrame in dataframes\n",
    "print(dataframes[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country    Gold  Silver  Bronze\n",
      "0  USA   United States  2088.0  1195.0  1052.0\n",
      "1  URS    Soviet Union   838.0   627.0   584.0\n",
      "2  GBR  United Kingdom   498.0   591.0   505.0\n",
      "3  FRA          France   378.0   461.0   475.0\n",
      "4  GER         Germany   407.0   350.0   454.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Make a copy of gold: medals\n",
    "medals = gold.copy()\n",
    "\n",
    "# Create list of new column labels: new_labels\n",
    "new_labels = ['NOC', 'Country', 'Gold']\n",
    "\n",
    "# Rename the columns of medals using new_labels\n",
    "medals.columns = new_labels\n",
    "\n",
    "# Add columns 'Silver' & 'Bronze' to medals\n",
    "medals['Silver'] = silver['Total']\n",
    "medals['Bronze'] = bronze['Total']\n",
    "\n",
    "# Print the head of medals\n",
    "print(medals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read 'monthly_max_temp.csv' into a DataFrame: weather1\n",
    "# weather1 = pd.read_csv('../datasets/pittsburgh2013.csv', index_col='Month')\n",
    "\n",
    "# # Print the head of weather1\n",
    "# print(weather1.head())\n",
    "\n",
    "# # Sort the index of weather1 in alphabetical order: weather2\n",
    "# weather2 = weather1.sort_index()\n",
    "\n",
    "# # Print the head of weather2\n",
    "# print(weather2.head())\n",
    "\n",
    "# # Sort the index of weather1 in reverse alphabetical order: weather3\n",
    "# weather3 = weather1.sort_index(ascending=False)\n",
    "\n",
    "# # Print the head of weather3\n",
    "# print(weather3.head())\n",
    "\n",
    "# # Sort weather1 numerically using the values of 'Max TemperatureF': weather4\n",
    "# weather4 = weather1.sort_values('Max TemperatureF')\n",
    "\n",
    "# # Print the head of weather4\n",
    "# print(weather4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1935, 1)\n",
      "(1587, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "names_1981 = pd.read_csv('../datasets/names1981.csv', header = None, names = ['name', 'gender', 'count'], index_col = (0, 1))\n",
    "names_1881 = pd.read_csv('../datasets/names1881.csv', header = None, names = ['name', 'gender', 'count'], index_col = (0, 1))\n",
    "\n",
    "# Reindex names_1981 with index of names_1881: common_names\n",
    "common_names = names_1981.reindex(names_1881.index)\n",
    "\n",
    "# Print shape of common_names\n",
    "print(common_names.shape)\n",
    "\n",
    "# Drop rows with null counts: common_names\n",
    "common_names = common_names.dropna()\n",
    "\n",
    "# Print shape of new common_names\n",
    "print(common_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min TemperatureC  Mean TemperatureC  Max TemperatureC\n",
      "0         -6.111111          -2.222222          0.000000\n",
      "1         -8.333333          -6.111111         -3.888889\n",
      "2         -8.888889          -4.444444          0.000000\n",
      "3         -2.777778          -2.222222         -1.111111\n",
      "4         -3.888889          -1.111111          1.111111\n"
     ]
    }
   ],
   "source": [
    "# Extract selected columns from weather as new DataFrame: temps_f\n",
    "\n",
    "weather = pd.read_csv('../datasets/pittsburgh2013.csv')\n",
    "temps_f = weather[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']]\n",
    "\n",
    "# Convert temps_f to celsius: temps_c\n",
    "temps_c = (temps_f -32) * 5/9\n",
    "\n",
    "# Rename 'F' in column names with 'C': temps_c.columns\n",
    "temps_c.columns = temps_c.columns.str.replace('F', 'C')\n",
    "\n",
    "# Print first 5 rows of temps_c\n",
    "print(temps_c.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2014-07-01  17569.4\n",
      "2014-10-01  17692.2\n",
      "2015-01-01  17783.6\n",
      "2015-04-01  17998.3\n",
      "2015-07-01  18141.9\n",
      "2015-10-01  18222.8\n",
      "2016-01-01  18281.6\n",
      "2016-04-01  18436.5\n",
      "              VALUE\n",
      "DATE               \n",
      "2008-12-31  14549.9\n",
      "2009-12-31  14566.5\n",
      "2010-12-31  15230.2\n",
      "2011-12-31  15785.3\n",
      "2012-12-31  16297.3\n",
      "2013-12-31  16999.9\n",
      "2014-12-31  17692.2\n",
      "2015-12-31  18222.8\n",
      "2016-12-31  18436.5\n",
      "              VALUE    growth\n",
      "DATE                         \n",
      "2008-12-31  14549.9       NaN\n",
      "2009-12-31  14566.5  0.114090\n",
      "2010-12-31  15230.2  4.556345\n",
      "2011-12-31  15785.3  3.644732\n",
      "2012-12-31  16297.3  3.243524\n",
      "2013-12-31  16999.9  4.311144\n",
      "2014-12-31  17692.2  4.072377\n",
      "2015-12-31  18222.8  2.999062\n",
      "2016-12-31  18436.5  1.172707\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'GDP.csv' into a DataFrame: gdp\n",
    "gdp = pd.read_csv('../datasets/gdp_usa.csv', index_col = 'DATE', parse_dates = True)\n",
    "\n",
    "# Slice all the gdp data from 2008 onward: post2008\n",
    "post2008 = gdp.loc['2008-01-01':, :]\n",
    "\n",
    "# Print the last 8 rows of post2008\n",
    "print(post2008.tail(8))\n",
    "\n",
    "# Resample post2008 by year, keeping last(): yearly\n",
    "yearly = post2008.resample('A').last()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# Compute percentage growth of yearly: yearly['growth']\n",
    "yearly['growth'] = yearly.pct_change() * 100\n",
    "\n",
    "# Print yearly again\n",
    "print(yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  2058.899902  2058.199951\n",
      "2015-01-05  2054.439941  2020.579956\n",
      "2015-01-06  2022.150024  2002.609985\n",
      "2015-01-07  2005.550049  2025.900024\n",
      "2015-01-08  2030.609985  2062.139893\n",
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  1340.364425  1339.908750\n",
      "2015-01-05  1348.616555  1326.389506\n",
      "2015-01-06  1332.515980  1319.639876\n",
      "2015-01-07  1330.562125  1344.063112\n",
      "2015-01-08  1343.268811  1364.126161\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'sp500.csv' into a DataFrame: sp500\n",
    "sp500 = pd.read_csv('../datasets/sp500.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Read 'exchange.csv' into a DataFrame: exchange\n",
    "exchange = pd.read_csv('../datasets/exchange.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Subset 'Open' & 'Close' columns from sp500: dollars\n",
    "dollars = sp500.loc[:, ['Open','Close']]\n",
    "\n",
    "# Print the head of dollars\n",
    "print(dollars.head())\n",
    "\n",
    "# Convert dollars to pounds: pounds\n",
    "pounds = dollars.multiply(exchange['GBP/USD'], axis = 'rows')\n",
    "\n",
    "# Print the head of pounds\n",
    "print(pounds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n",
      "642\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('../datasets/sales-jan-2015.csv', parse_dates = True, index_col = 'Date')\n",
    "\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('../datasets/sales-feb-2015.csv', parse_dates = True, index_col = 'Date')\n",
    "\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('../datasets/sales-mar-2015.csv', parse_dates = True, index_col = 'Date')\n",
    "\n",
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']\n",
    "\n",
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "\n",
    "# Print the second slice from quarter1\n",
    "print(quarter1.loc['feb 26, 2015': 'mar 7, 2015'])\n",
    "\n",
    "# Compute & print total sales in quarter1\n",
    "print(quarter1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month['Units'])\n",
    "\n",
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat(units, axis = 'rows')\n",
    "\n",
    "# Print slices from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 2)\n",
      "(1935, 2)\n",
      "(21390, 2)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f6fb44082151>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Print all rows that contain the name 'Morgan'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcombined_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Morgan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "# Add 'year' column to names_1881 & names_1981\n",
    "names_1881['year'] = 1881\n",
    "names_1981['year'] = 1981\n",
    "\n",
    "# Append names_1981 after names_1881 with ignore_index=True: combined_names\n",
    "combined_names = names_1881.append(names_1981, ignore_index=False)\n",
    "\n",
    "# Print shapes of names_1981, names_1881, and combined_names\n",
    "print(names_1981.shape)\n",
    "print(names_1881.shape)\n",
    "print(combined_names.shape)\n",
    "\n",
    "# Print all rows that contain the name 'Morgan'\n",
    "print(combined_names.loc[combined_names['name']=='Morgan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    count\n",
      "name      gender         \n",
      "Mary      F       11030.0\n",
      "Anna      F        5182.0\n",
      "Emma      F         532.0\n",
      "Elizabeth F       20168.0\n",
      "Margaret  F        2791.0\n",
      "...                   ...\n",
      "Wells     M           6.0\n",
      "Wiliam    M          11.0\n",
      "Wilton    M          33.0\n",
      "Wing      M           8.0\n",
      "Wright    M           6.0\n",
      "\n",
      "[1587 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(common_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initialize an empyy list: medals\n",
    "# medals =[]\n",
    "medal_types = ['silver', 'gold', 'bronze']\n",
    "\n",
    "# for medal in medal_types:\n",
    "#     # Create the file name: file_name\n",
    "#     file_name = \"%s_top5.csv\" % medal\n",
    "#     # Create list of column names: columns\n",
    "#     columns = ['Country', medal]\n",
    "#     # Read file_name into a DataFrame: medal_df\n",
    "#     medal_df = pd.read_csv(file_name, header = 0,        index_col= 'Country', names = columns)\n",
    "#     # Append medal_df to medals\n",
    "#     medals.append(medal_df)\n",
    "\n",
    "# # Concatenate medals horizontally: medals_df\n",
    "# medals_df = pd.concat(medals, axis = 'columns')\n",
    "\n",
    "# # Print medals_df\n",
    "# print(medals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for medal in medal_types:\n",
    "\n",
    "#     file_name = \"%s_top5.csv\" % medal\n",
    "    \n",
    "#     # Read file_name into a DataFrame: medal_df\n",
    "#     medal_df = pd.read_csv(file_name, index_col = 'Country')\n",
    "    \n",
    "#     # Append medal_df to medals\n",
    "#     medals.append(medal_df)\n",
    "    \n",
    "# # Concatenate medals: medals\n",
    "# medals = pd.concat(medals, keys=['bronze', 'silver', 'gold'])\n",
    "\n",
    "# # Print medals in entirety\n",
    "# print(medals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort the entries of medals: medals_sorted\n",
    "# medals_sorted = medals.sort_index(level=0)\n",
    "\n",
    "# # Print the number of Bronze medals won by Germany\n",
    "# print(medals_sorted.loc[('bronze','Germany')])\n",
    "\n",
    "# # Print data about silver medals\n",
    "# print(medals_sorted.loc['silver'])\n",
    "\n",
    "# # Create alias for pd.IndexSlice: idx\n",
    "# idx = pd.IndexSlice\n",
    "\n",
    "# # Print all the data on medals won by the United Kingdom\n",
    "# print(medals_sorted.loc[idx[:, 'United Kingdom'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Units\n",
      "         Company               \n",
      "january  Acme Coporation     76\n",
      "         Hooli               70\n",
      "         Initech             37\n",
      "         Mediacore           15\n",
      "         Streeplex           50\n",
      "february Acme Coporation     34\n",
      "         Hooli               30\n",
      "         Initech             30\n",
      "         Mediacore           45\n",
      "         Streeplex           37\n",
      "march    Acme Coporation      5\n",
      "         Hooli               37\n",
      "         Initech             68\n",
      "         Mediacore           68\n",
      "         Streeplex           40\n",
      "                    Units\n",
      "         Company         \n",
      "january  Mediacore     15\n",
      "february Mediacore     45\n",
      "march    Mediacore     68\n"
     ]
    }
   ],
   "source": [
    "# Make the list of tuples: month_list\n",
    "month_list = [('january', jan), ('february', feb), ('march', mar)]\n",
    "\n",
    "# Create an empty dictionary: month_dict\n",
    "month_dict = {}\n",
    "\n",
    "for month_name, month_data in month_list:\n",
    "\n",
    "    # Group month_data: month_dict[month_name]\n",
    "    month_dict[month_name] = month_data.groupby('Company').sum()\n",
    "\n",
    "# Concatenate data in month_dict: sales\n",
    "sales = pd.concat(month_dict)\n",
    "\n",
    "# Print sales\n",
    "print(sales)\n",
    "\n",
    "# Print all sales by Mediacore\n",
    "idx = pd.IndexSlice\n",
    "print(sales.loc[idx[:, 'Mediacore'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bronze                               silver                                \\\n",
      "       NOC               Country   Total    NOC               Country   Total   \n",
      "0      USA         United States  1052.0    USA         United States  1195.0   \n",
      "1      URS          Soviet Union   584.0    URS          Soviet Union   627.0   \n",
      "2      GBR        United Kingdom   505.0    GBR        United Kingdom   591.0   \n",
      "3      FRA                France   475.0    FRA                France   461.0   \n",
      "4      GER               Germany   454.0    GER               Germany   350.0   \n",
      "..     ...                   ...     ...    ...                   ...     ...   \n",
      "133    SEN               Senegal     NaN    SEN               Senegal     1.0   \n",
      "134    SUD                 Sudan     NaN    SUD                 Sudan     1.0   \n",
      "135    TGA                 Tonga     NaN    TGA                 Tonga     1.0   \n",
      "136    BDI               Burundi     NaN    BDI               Burundi     NaN   \n",
      "137    UAE  United Arab Emirates     NaN    UAE  United Arab Emirates     NaN   \n",
      "\n",
      "    gold                                \n",
      "     NOC               Country   Total  \n",
      "0    USA         United States  2088.0  \n",
      "1    URS          Soviet Union   838.0  \n",
      "2    GBR        United Kingdom   498.0  \n",
      "3    FRA                France   378.0  \n",
      "4    GER               Germany   407.0  \n",
      "..   ...                   ...     ...  \n",
      "133  SEN               Senegal     NaN  \n",
      "134  SUD                 Sudan     NaN  \n",
      "135  TGA                 Tonga     NaN  \n",
      "136  BDI               Burundi     1.0  \n",
      "137  UAE  United Arab Emirates     1.0  \n",
      "\n",
      "[138 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the list of DataFrames: medal_list\n",
    "medal_list = [bronze,silver, gold]\n",
    "\n",
    "# Concatenate medal_list horizontally using an inner join: medals\n",
    "medals = pd.concat(medal_list, keys = ['bronze', 'silver', 'gold'], axis = 1,join = 'inner')\n",
    "\n",
    "# Print medals\n",
    "print(medals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>59.184116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>49.557050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1962-01-01</td>\n",
       "      <td>46.685179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1963-01-01</td>\n",
       "      <td>50.097303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1964-01-01</td>\n",
       "      <td>59.062255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GDP\n",
       "Year                 \n",
       "1960-01-01  59.184116\n",
       "1961-01-01  49.557050\n",
       "1962-01-01  46.685179\n",
       "1963-01-01  50.097303\n",
       "1964-01-01  59.062255"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china = pd.read_csv('../datasets/gdp_china.csv', parse_dates=True, index_col = 'Year')\n",
    "\n",
    "china.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>China</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>59.184116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>49.557050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1962-01-01</td>\n",
       "      <td>46.685179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1963-01-01</td>\n",
       "      <td>50.097303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1964-01-01</td>\n",
       "      <td>59.062255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                China\n",
       "Year                 \n",
       "1960-01-01  59.184116\n",
       "1961-01-01  49.557050\n",
       "1962-01-01  46.685179\n",
       "1963-01-01  50.097303\n",
       "1964-01-01  59.062255"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china = china.rename(columns={\"GDP\": \"China\"})\n",
    "\n",
    "china.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1947-01-01</td>\n",
       "      <td>243.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-04-01</td>\n",
       "      <td>246.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-07-01</td>\n",
       "      <td>250.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-10-01</td>\n",
       "      <td>260.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>266.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VALUE\n",
       "Year             \n",
       "1947-01-01  243.1\n",
       "1947-04-01  246.3\n",
       "1947-07-01  250.1\n",
       "1947-10-01  260.3\n",
       "1948-01-01  266.2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us = pd.read_csv('../datasets/gdp_usa.csv', index_col = 'DATE', parse_dates = True)\n",
    "\n",
    "us['Year'] = us.index\n",
    "\n",
    "us = us.reindex(us.Year)\n",
    "\n",
    "# us.head()\n",
    "us = us.loc[:, ['VALUE']]\n",
    "\n",
    "us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1947-01-01</td>\n",
       "      <td>243.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-04-01</td>\n",
       "      <td>246.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-07-01</td>\n",
       "      <td>250.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-10-01</td>\n",
       "      <td>260.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>266.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US\n",
       "Year             \n",
       "1947-01-01  243.1\n",
       "1947-04-01  246.3\n",
       "1947-07-01  250.1\n",
       "1947-10-01  260.3\n",
       "1948-01-01  266.2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us = us.rename(columns={'VALUE':'US'})\n",
    "\n",
    "us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               China        US\n",
      "Year                          \n",
      "1970-12-31  0.546128  1.017187\n",
      "1980-12-31  1.072537  1.742556\n",
      "1990-12-31  0.892820  1.012126\n",
      "2000-12-31  2.357522  0.738632\n",
      "2010-12-31  4.011081  0.454332\n",
      "2020-12-31  3.789936  0.361780\n"
     ]
    }
   ],
   "source": [
    "# Resample and tidy china: china_annual\n",
    "\n",
    "# china = pd.read_csv('../datasets/gdp_china.csv')\n",
    "china_annual = china.resample('A').last().pct_change(10).dropna()\n",
    "\n",
    "# Resample and tidy us: us_annual\n",
    "us_annual = us.resample('A').last().pct_change(10).dropna()\n",
    "\n",
    "# Concatenate china_annual and us_annual: gdp\n",
    "gdp = pd.concat([china_annual, us_annual], axis=1, join='inner')\n",
    "\n",
    "# Resample gdp and print\n",
    "print(gdp.resample('10A').last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1947-01-01</td>\n",
       "      <td>243.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-04-01</td>\n",
       "      <td>246.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-07-01</td>\n",
       "      <td>250.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1947-10-01</td>\n",
       "      <td>260.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>266.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US\n",
       "Year             \n",
       "1947-01-01  243.1\n",
       "1947-04-01  246.3\n",
       "1947-07-01  250.1\n",
       "1947-10-01  260.3\n",
       "1948-01-01  266.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['1947-01-01', '1947-04-01', '1947-07-01', '1947-10-01',\n",
      "               '1948-01-01', '1948-04-01', '1948-07-01', '1948-10-01',\n",
      "               '1949-01-01', '1949-04-01',\n",
      "               ...\n",
      "               '2014-01-01', '2014-04-01', '2014-07-01', '2014-10-01',\n",
      "               '2015-01-01', '2015-04-01', '2015-07-01', '2015-10-01',\n",
      "               '2016-01-01', '2016-04-01'],\n",
      "              dtype='datetime64[ns]', name='Year', length=278, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(us.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Edition  Grand Total         City                     Country\n",
      "0      1896          151       Athens                      Greece\n",
      "1      1900          512        Paris                      France\n",
      "2      1904          470    St. Louis               United States\n",
      "3      1908          804       London              United Kingdom\n",
      "4      1912          885    Stockholm                      Sweden\n",
      "5      1920         1298      Antwerp                     Belgium\n",
      "6      1924          884        Paris                      France\n",
      "7      1928          710    Amsterdam                 Netherlands\n",
      "8      1932          615  Los Angeles               United States\n",
      "9      1936          875       Berlin                     Germany\n",
      "10     1948          814       London              United Kingdom\n",
      "11     1952          889     Helsinki                     Finland\n",
      "12     1956          885    Melbourne                   Australia\n",
      "13     1960          882         Rome                       Italy\n",
      "14     1964         1010        Tokyo                       Japan\n",
      "15     1968         1031  Mexico City                      Mexico\n",
      "16     1972         1185       Munich  West Germany (now Germany)\n",
      "17     1976         1305     Montreal                      Canada\n",
      "18     1980         1387       Moscow       U.S.S.R. (now Russia)\n",
      "19     1984         1459  Los Angeles               United States\n",
      "20     1988         1546        Seoul                 South Korea\n",
      "21     1992         1705    Barcelona                       Spain\n",
      "22     1996         1859      Atlanta               United States\n",
      "23     2000         2015       Sydney                   Australia\n",
      "24     2004         1998       Athens                      Greece\n",
      "25     2008         2042      Beijing                       China\n"
     ]
    }
   ],
   "source": [
    "#Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create file path: file_path\n",
    "file_path = '../datasets/Summer Olympic medalists 1896 to 2008 - EDITIONS.tsv'\n",
    "\n",
    "# Load DataFrame from file_path: editions\n",
    "editions = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Extract the relevant columns: editions\n",
    "editions = editions[['Edition', 'Grand Total', 'City', 'Country']]\n",
    "\n",
    "# Print editions DataFrame\n",
    "print(editions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country  NOC\n",
      "0      Afghanistan  AFG\n",
      "1          Albania  ALB\n",
      "2          Algeria  ALG\n",
      "3  American Samoa*  ASA\n",
      "4          Andorra  AND\n",
      "             Country  NOC\n",
      "196          Vietnam  VIE\n",
      "197  Virgin Islands*  ISV\n",
      "198            Yemen  YEM\n",
      "199           Zambia  ZAM\n",
      "200         Zimbabwe  ZIM\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Create the file path: file_path\n",
    "file_path = '../datasets/Summer Olympic medalists 1896 to 2008 - IOC COUNTRY CODES.csv'\n",
    "\n",
    "# Load DataFrame from file_path: ioc_codes\n",
    "ioc_codes = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the relevant columns: ioc_codes\n",
    "ioc_codes = ioc_codes[['Country', 'NOC']]\n",
    "\n",
    "# Print first and last 5 rows of ioc_codes\n",
    "print(ioc_codes.head())\n",
    "print(ioc_codes.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pandas\n",
    "# # import pandas as pd\n",
    "\n",
    "# # Create empty dictionary: medals_dict\n",
    "# medals_dict = {}\n",
    "\n",
    "# for year in editions['Edition']:\n",
    "\n",
    "#     # Create the file path: file_path\n",
    "#     file_path = '../datasets/summer_{:d}.csv'.format(year)\n",
    "    \n",
    "#     # Load file_path into a DataFrame: medals_dict[year]\n",
    "#     medals_dict[year] = pd.read_csv(file_path)\n",
    "    \n",
    "#     # Extract relevant columns: medals_dict[year]\n",
    "#     medals_dict[year] = medals_dict[year][['Athlete',     'NOC', 'Medal']]\n",
    "    \n",
    "#     # Assign year to column 'Edition' of medals_dict\n",
    "#     medals_dict[year]['Edition'] = year\n",
    "    \n",
    "# # Concatenate medals_dict: medals\n",
    "# medals = pd.concat(medals_dict, ignore_index= True)\n",
    "\n",
    "# # Print first and last 5 rows of medals\n",
    "# print(medals.head())\n",
    "# print(medals.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct the pivot_table: medal_counts\n",
    "# medal_counts = medals.pivot_table(index= 'Edition', values='Athlete', columns='NOC', aggfunc='count')\n",
    "\n",
    "# # Print the first & last 5 rows of medal_counts\n",
    "# print(medal_counts.head())\n",
    "# print(medal_counts.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Index of editions: totals\n",
    "# totals = editions.set_index('Edition')\n",
    "\n",
    "# # Reassign totals['Grand Total']: totals\n",
    "# totals = totals['Grand Total']\n",
    "\n",
    "# # Divide medal_counts by totals: fractions\n",
    "# fractions = medal_counts.divide(totals, axis='rows')\n",
    "\n",
    "# # Print first & last 5 rows of fractions\n",
    "# print(fractions.head())\n",
    "# print(fractions.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the expanding mean: mean_fractions\n",
    "# mean_fractions = fractions.expanding().mean()\n",
    "\n",
    "# # Compute the percentage change: fractions_change\n",
    "# fractions_change = mean_fractions.pct_change()*100\n",
    "\n",
    "# # Reset the index of fractions_change: fractions_change\n",
    "# fractions_change = fractions_change.reset_index()\n",
    "\n",
    "# # Print first & last 5 rows of fractions_change\n",
    "# print(fractions_change.head())\n",
    "# print(fractions_change.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Left join editions and ioc_codes: hosts\n",
    "# hosts = pd.merge(editions, ioc_codes, how='left')\n",
    "\n",
    "# # Extract relevant columns and set index: hosts\n",
    "# hosts = hosts.loc[:, ['Edition', 'NOC']].set_index('Edition')\n",
    "\n",
    "# # Fix missing 'NOC' values of hosts\n",
    "# print(hosts.loc[hosts.NOC.isnull()])\n",
    "# hosts.loc[1972, 'NOC'] = 'FRG'\n",
    "# hosts.loc[1980, 'NOC'] = 'URS'\n",
    "# hosts.loc[1988, 'NOC'] = 'KOR'\n",
    "\n",
    "# # Reset Index of hosts: hosts\n",
    "# hosts = hosts.reset_index()\n",
    "\n",
    "# # Print hosts\n",
    "# print(hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Reshape fractions_change: reshaped\n",
    "# reshaped = pd.melt(fractions_change, id_vars='Edition', value_name='Change')\n",
    "\n",
    "# # Print reshaped.shape and fractions_change.shape\n",
    "# print(reshaped.shape, fractions_change.shape)\n",
    "\n",
    "# # Extract rows from reshaped where 'NOC' == 'CHN': chn\n",
    "# chn = reshaped[reshaped['NOC']=='CHN']\n",
    "\n",
    "# # Print last 5 rows of chn with .tail()\n",
    "# print(chn.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Merge reshaped and hosts: merged\n",
    "# merged = pd.merge(reshaped, hosts, how='inner')\n",
    "\n",
    "# # Print first 5 rows of merged\n",
    "# print(merged.head())\n",
    "\n",
    "# # Set Index of merged and sort it: influence\n",
    "# influence = merged.set_index('Edition').sort_index()\n",
    "\n",
    "# # Print first 5 rows of influence\n",
    "# print(influence.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pyplot\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Extract influence['Change']: change\n",
    "# change = influence['Change']\n",
    "\n",
    "# # Make bar plot of change: ax\n",
    "# ax = change.plot(kind='bar')\n",
    "\n",
    "# # Customize the plot to improve readability\n",
    "# ax.set_ylabel(\"% Change of Host Country Medal Count\")\n",
    "# ax.set_title(\"Is there a Host Country Advantage?\")\n",
    "# ax.set_xticklabels(editions['City'])\n",
    "\n",
    "# # Display the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
